"""
Main ML Pipeline - Customer Churn Prediction

This script orchestrates the complete ML pipeline by importing
the generated preprocessing, training, and evaluation modules.

Auto-generated by AI-Playground
"""

import pandas as pd
import numpy as np
from pathlib import Path
import pickle

# Import generated modules
from preprocess import preprocess_data
from train import split_data, train_model, save_model, load_model, predict
from evaluate import evaluate_model, save_results

# Configuration
DATA_PATH = 'customer_data.csv'
MODEL_PATH = 'models/churn_model.pkl'
RESULTS_PATH = 'results/evaluation_results.json'
RANDOM_STATE = 42


def run_complete_pipeline(data_path: str = DATA_PATH):
    """
    Run the complete ML pipeline from data loading to evaluation.
    
    Args:
        data_path: Path to the input data CSV
    
    Returns:
        Dictionary containing model and evaluation results
    """
    print("=" * 80)
    print("Customer Churn Prediction - Complete ML Pipeline")
    print("=" * 80)
    
    # Step 1: Load data
    print("\n[1/5] Loading data...")
    df = pd.read_csv(data_path)
    print(f"Loaded {len(df)} rows, {len(df.columns)} columns")
    
    # Step 2: Preprocess data
    print("\n[2/5] Preprocessing data...")
    df_processed = preprocess_data(df)
    print(f"Processed shape: {df_processed.shape}")
    
    # Step 3: Split data
    print("\n[3/5] Splitting data...")
    X_train, X_test, y_train, y_test = split_data(df_processed, target_column='churn')
    print(f"Train: {len(X_train)} samples, Test: {len(X_test)} samples")
    
    # Step 4: Train model
    print("\n[4/5] Training model...")
    model = train_model(X_train, y_train, verbose=True)
    
    # Save model
    save_model(model, MODEL_PATH)
    
    # Step 5: Evaluate model
    print("\n[5/5] Evaluating model...")
    y_pred = predict(model, X_test)
    y_proba = model.predict_proba(X_test) if hasattr(model, 'predict_proba') else None
    
    results = evaluate_model(model, X_test, y_test, y_pred=y_pred, y_proba=y_proba)
    
    # Save evaluation results
    save_results(results, RESULTS_PATH)
    
    print("\n" + "=" * 80)
    print("Pipeline completed successfully!")
    print("=" * 80)
    print(f"\nModel saved to: {MODEL_PATH}")
    print(f"Results saved to: {RESULTS_PATH}")
    
    return {
        'model': model,
        'results': results,
        'test_data': (X_test, y_test)
    }


def predict_new_data(data_path: str, model_path: str = MODEL_PATH):
    """
    Load a trained model and make predictions on new data.
    
    Args:
        data_path: Path to new data CSV
        model_path: Path to saved model
    
    Returns:
        Predictions array
    """
    print(f"Loading model from {model_path}...")
    model = load_model(model_path)
    
    print(f"Loading data from {data_path}...")
    df = pd.read_csv(data_path)
    
    print("Preprocessing data...")
    df_processed = preprocess_data(df)
    
    print("Making predictions...")
    predictions = predict(model, df_processed)
    
    # Get probabilities if available
    if hasattr(model, 'predict_proba'):
        probabilities = model.predict_proba(df_processed)
        return predictions, probabilities
    
    return predictions


def retrain_model(data_path: str = DATA_PATH):
    """
    Retrain the model with new data.
    
    Args:
        data_path: Path to the training data CSV
    
    Returns:
        Trained model
    """
    print("Retraining model...")
    
    # Load and preprocess data
    df = pd.read_csv(data_path)
    df_processed = preprocess_data(df)
    
    # Split data
    X_train, X_test, y_train, y_test = split_data(df_processed, target_column='churn')
    
    # Train model
    model = train_model(X_train, y_train, X_val=X_test, y_val=y_test, verbose=True)
    
    # Save model
    save_model(model, MODEL_PATH)
    
    print(f"Model retrained and saved to {MODEL_PATH}")
    return model


if __name__ == '__main__':
    import sys
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == 'train':
            # Run complete pipeline
            run_complete_pipeline()
        
        elif command == 'predict':
            # Make predictions on new data
            if len(sys.argv) < 3:
                print("Usage: python main.py predict <data_path>")
                sys.exit(1)
            
            data_path = sys.argv[2]
            predictions = predict_new_data(data_path)
            print(f"\nPredictions: {predictions}")
        
        elif command == 'retrain':
            # Retrain model
            retrain_model()
        
        else:
            print(f"Unknown command: {command}")
            print("Available commands: train, predict, retrain")
    
    else:
        # Default: run complete pipeline
        run_complete_pipeline()
