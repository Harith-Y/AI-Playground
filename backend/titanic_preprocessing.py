# Auto-generated by AI-Playground
# Generated: 2025-12-30T21:33:31.962081
# Experiment: Titanic Survival Prediction

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split


from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder
from sklearn.impute import SimpleImputer



import pickle
import json
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Set random seed for reproducibility
RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)


# ============================================================================
# DATA LOADING
# ============================================================================

def load_data(file_path: str) -> pd.DataFrame:
    """
    Load dataset from file.
    
    Args:
        file_path: Path to the dataset file
    
    Returns:
        Loaded DataFrame
    """
    print(f"Loading data from {file_path}...")
    
    
    df = pd.read_csv(file_path)
    
    
    print(f"Loaded {len(df)} rows and {len(df.columns)} columns")
    print(f"Columns: {list(df.columns)}")
    
    return df


# Load the dataset
df = load_data('titanic.csv')

# Display basic information
print("\nDataset Info:")
print(df.info())
print("\nFirst few rows:")
print(df.head())
print("\nBasic statistics:")
print(df.describe())


# ============================================================================
# DATA PREPROCESSING
# ============================================================================

def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Apply preprocessing steps to the dataset.
    
    Args:
        df: Input DataFrame
    
    Returns:
        Preprocessed DataFrame
    """
    df = df.copy()
    print("\nApplying preprocessing steps...")
    
    
    # Step 1: Impute Age
    print(f"  - Impute missing values using median strategy")
    
    # Handle missing values in Age
    from sklearn.impute import SimpleImputer
    imputer = SimpleImputer(strategy='median')
    df[['Age']] = imputer.fit_transform(df[['Age']])
    
    
    
    
    # Step 2: Impute Embarked
    print(f"  - Impute missing values using mode strategy")
    
    # Handle missing values in Embarked
    from sklearn.impute import SimpleImputer
    imputer = SimpleImputer(strategy='mode')
    df[['Embarked']] = imputer.fit_transform(df[['Embarked']])
    
    
    
    
    # Step 3: Encode Categorical
    print(f"  - Encode categorical features using onehot encoding")
    
    # Encode categorical features: Sex, Embarked, Pclass
    
    from sklearn.preprocessing import OneHotEncoder
    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
    encoded = encoder.fit_transform(df[['Sex', 'Embarked', 'Pclass']])
    encoded_df = pd.DataFrame(
        encoded,
        columns=encoder.get_feature_names_out(['Sex', 'Embarked', 'Pclass']),
        index=df.index
    )
    df = df.drop(columns=['Sex', 'Embarked', 'Pclass'])
    df = pd.concat([df, encoded_df], axis=1)
    
    
    
    
    
    # Step 4: Scale Numerical
    print(f"  - Scale features using standard scaler")
    
    # Scale features: Age, Fare, SibSp, Parch
    
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    
    df[['Age', 'Fare', 'SibSp', 'Parch']] = scaler.fit_transform(df[['Age', 'Fare', 'SibSp', 'Parch']])
    
    
    
    
    
    print(f"Preprocessing complete. Shape: {df.shape}")
    return df


# Apply preprocessing
df = preprocess_data(df)