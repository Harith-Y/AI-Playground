# Auto-generated by AI-Playground
# Generated: 2025-12-30T23:48:19.393221
# Experiment: Titanic Survival Prediction

import numpy as np
import pandas as pd
import pickle
from pathlib import Path
from typing import Union, List, Dict, Any, Optional
import warnings
warnings.filterwarnings('ignore')

# Preprocessing imports
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
from sklearn.preprocessing import OneHotEncoder, LabelEncoder


# ============================================================================
# LOAD MODEL
# ============================================================================

def load_model(model_path: str = 'models/titanic_model.pkl'):
    """
    Load trained model from file.
    
    Args:
        model_path: Path to the saved model file
    
    Returns:
        Loaded model
    """
    print(f"Loading model from {model_path}...")
    
    with open(model_path, 'rb') as f:
        model = pickle.load(f)
    
    print(f"Model loaded successfully!")
    return model

def load_preprocessor(preprocessor_path: str = 'models/titanic_preprocessor.pkl'):
    """
    Load preprocessing pipeline from file.
    
    Args:
        preprocessor_path: Path to the saved preprocessor file
    
    Returns:
        Loaded preprocessor
    """
    print(f"Loading preprocessor from {preprocessor_path}...")
    
    with open(preprocessor_path, 'rb') as f:
        preprocessor = pickle.load(f)
    
    print(f"Preprocessor loaded successfully!")
    return preprocessor


# ============================================================================
# CLASSIFICATION PREDICTION
# ============================================================================

def predict(
    model,
    X: Union[np.ndarray, pd.DataFrame],
    return_probabilities: bool = True
) -> Dict[str, Any]:
    """
    Make predictions using the trained classification model.
    
    Args:
        model: Trained model
        X: Input features (numpy array or pandas DataFrame)
        return_probabilities: Whether to return class probabilities
    
    Returns:
        Dictionary containing predictions and optionally probabilities
    """
    print(f"Making predictions on {len(X)} samples...")
    
    # Get predictions
    predictions = model.predict(X)
    
    results = {
        'predictions': predictions.tolist() if isinstance(predictions, np.ndarray) else predictions,
        'n_samples': len(X)
    }
    
    # Get probabilities if requested and available
    if return_probabilities and hasattr(model, 'predict_proba'):
        probabilities = model.predict_proba(X)
        results['probabilities'] = probabilities.tolist() if isinstance(probabilities, np.ndarray) else probabilities
        
        # Get predicted class names if available
        if hasattr(model, 'classes_'):
            results['classes'] = model.classes_.tolist()
    
    print(f"Predictions complete!")
    return results

def predict_with_preprocessing(
    model,
    preprocessor,
    X: Union[np.ndarray, pd.DataFrame],
    return_probabilities: bool = True
) -> Dict[str, Any]:
    """
    Preprocess data and make predictions.
    
    Args:
        model: Trained model
        preprocessor: Fitted preprocessor
        X: Raw input features
        return_probabilities: Whether to return class probabilities
    
    Returns:
        Dictionary containing predictions and optionally probabilities
    """
    print("Preprocessing input data...")
    X_processed = preprocessor.transform(X)
    
    return predict(model, X_processed, return_probabilities)


# ============================================================================
# BATCH PREDICTION
# ============================================================================

def predict_batch(
    model,
    data_path: str,
    output_path: str = 'predictions/titanic_predictions.csv',
    batch_size: int = 1000
) -> pd.DataFrame:
    """
    Make predictions on a large dataset in batches.
    
    Args:
        model: Trained model
        data_path: Path to input data file
        output_path: Path to save predictions
        batch_size: Number of samples to process at once
    
    Returns:
        DataFrame with predictions
    """
    print(f"Loading data from {data_path}...")
    
    # Load data based on format
    if data_path.endswith('.csv'):
        df = pd.read_csv(data_path)
    elif data_path.endswith('.parquet'):
        df = pd.read_parquet(data_path)
    elif data_path.endswith('.json'):
        df = pd.read_json(data_path)
    else:
        raise ValueError(f"Unsupported file format: {data_path}")
    
    print(f"Loaded {len(df)} samples")
    
    # Process in batches
    all_predictions = []
    n_batches = (len(df) + batch_size - 1) // batch_size
    
    for i in range(0, len(df), batch_size):
        batch_num = i // batch_size + 1
        print(f"Processing batch {batch_num}/{n_batches}...")
        
        batch = df.iloc[i:i+batch_size]
        results = predict(model, batch)
        all_predictions.extend(results['predictions'])
    
    # Add predictions to dataframe
    df['prediction'] = all_predictions
    
    # Save results
    print(f"Saving predictions to {output_path}...")
    df.to_csv(output_path, index=False)
    print(f"Predictions saved!")
    
    return df


# ============================================================================
# SAVE PREDICTIONS
# ============================================================================

def save_predictions(
    predictions: Dict[str, Any],
    output_path: str = 'predictions/titanic_predictions.csv',
    include_metadata: bool = True
) -> None:
    """
    Save predictions to file.
    
    Args:
        predictions: Dictionary containing predictions
        output_path: Path to save predictions
        include_metadata: Whether to include metadata
    """
    # Ensure directory exists
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    
    # Convert to DataFrame
    df = pd.DataFrame({'prediction': predictions['predictions']})
    
    # Add probabilities if available
    if 'probabilities' in predictions:
        probs = predictions['probabilities']
        if 'classes' in predictions:
            classes = predictions['classes']
            for i, cls in enumerate(classes):
                df[f'prob_{cls}'] = [p[i] for p in probs]
        else:
            for i in range(len(probs[0])):
                df[f'prob_class_{i}'] = [p[i] for p in probs]
    
    # Save to CSV
    df.to_csv(output_path, index=False)
    print(f"Predictions saved to {output_path}")
    
    # Save metadata if requested
    if include_metadata:
        metadata_path = output_path.replace('.csv', '_metadata.json')
        import json
        metadata = {
            'n_samples': predictions['n_samples'],
            'timestamp': '2025-12-30T23:48:19.393221',
            'task_type': 'classification'
        }
        
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        
        print(f"Metadata saved to {metadata_path}")


# ============================================================================
# MAIN EXECUTION
# ============================================================================

if __name__ == '__main__':
    """
    Example usage of prediction functions.
    """
    print("=" * 80)
    print("Prediction Script - Titanic Survival Prediction")
    print("=" * 80)
    
    # Example: Load model and make predictions
    # model = load_model('models/titanic_model.pkl')
    
    # Load new data
    # X_new = pd.read_csv('new_data.csv')
    
    # Make predictions
    # results = predict(model, X_new)
    
    # Save predictions
    # save_predictions(results, 'predictions/titanic_predictions.csv')
    
    # Or use batch prediction for large datasets
    # df_with_predictions = predict_batch(model, 'large_dataset.csv', 'predictions.csv')
    
    print("\nPrediction script ready!")
    print("Uncomment the example code above to run predictions.")
