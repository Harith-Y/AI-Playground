"""
Prediction Module - Customer Segmentation

Auto-generated by AI-Playground
Generated: 2025-12-30T23:48:19.388887
Task Type: clustering

This module can be imported and used in other scripts:
    from predict import load_model, predict, predict_batch
"""


# Auto-generated by AI-Playground
# Generated: 2025-12-30T23:48:19.388887
# Experiment: Customer Segmentation

import numpy as np
import pandas as pd
import pickle
from pathlib import Path
from typing import Union, List, Dict, Any, Optional
import warnings
warnings.filterwarnings('ignore')



# Configuration
MODEL_PATH = 'models/clustering_model.pkl'
OUTPUT_PATH = 'predictions.csv'


# ============================================================================
# LOAD MODEL
# ============================================================================

def load_model(model_path: str = 'models/clustering_model.pkl'):
    """
    Load trained model from file.
    
    Args:
        model_path: Path to the saved model file
    
    Returns:
        Loaded model
    """
    print(f"Loading model from {model_path}...")
    
    with open(model_path, 'rb') as f:
        model = pickle.load(f)
    
    print(f"Model loaded successfully!")
    return model


# ============================================================================
# CLUSTERING PREDICTION
# ============================================================================

def predict(
    model,
    X: Union[np.ndarray, pd.DataFrame]
) -> Dict[str, Any]:
    """
    Assign cluster labels using the trained clustering model.
    
    Args:
        model: Trained clustering model
        X: Input features (numpy array or pandas DataFrame)
    
    Returns:
        Dictionary containing cluster assignments
    """
    print(f"Assigning clusters for {len(X)} samples...")
    
    # Get cluster assignments
    if hasattr(model, 'predict'):
        labels = model.predict(X)
    elif hasattr(model, 'labels_'):
        # For models that don't have predict (like some clustering algorithms)
        labels = model.labels_
    else:
        raise ValueError("Model does not support prediction")
    
    # Get cluster statistics
    unique_labels, counts = np.unique(labels, return_counts=True)
    cluster_distribution = dict(zip(unique_labels.tolist(), counts.tolist()))
    
    results = {
        'cluster_labels': labels.tolist() if isinstance(labels, np.ndarray) else labels,
        'n_samples': len(X),
        'n_clusters': len(unique_labels),
        'cluster_distribution': cluster_distribution
    }
    
    print(f"Cluster assignment complete!")
    return results


# ============================================================================
# SAVE PREDICTIONS
# ============================================================================

def save_predictions(
    predictions: Dict[str, Any],
    output_path: str = 'predictions.csv',
    include_metadata: bool = True
) -> None:
    """
    Save predictions to file.
    
    Args:
        predictions: Dictionary containing predictions
        output_path: Path to save predictions
        include_metadata: Whether to include metadata
    """
    # Ensure directory exists
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    
    # Convert to DataFrame
    df = pd.DataFrame({'prediction': predictions['predictions']})
    
    # Add probabilities if available
    if 'probabilities' in predictions:
        probs = predictions['probabilities']
        if 'classes' in predictions:
            classes = predictions['classes']
            for i, cls in enumerate(classes):
                df[f'prob_{cls}'] = [p[i] for p in probs]
        else:
            for i in range(len(probs[0])):
                df[f'prob_class_{i}'] = [p[i] for p in probs]
    
    # Save to CSV
    df.to_csv(output_path, index=False)
    print(f"Predictions saved to {output_path}")
    
    # Save metadata if requested
    if include_metadata:
        metadata_path = output_path.replace('.csv', '_metadata.json')
        import json
        metadata = {
            'n_samples': predictions['n_samples'],
            'timestamp': '2025-12-30T23:48:19.388887',
            'task_type': 'clustering'
        }
        
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        
        print(f"Metadata saved to {metadata_path}")



if __name__ == '__main__':
    """
    Example usage when run as a script.
    """
    print("=" * 80)
    print("Prediction Module - Customer Segmentation")
    print("=" * 80)
    
    # Example: Load model and make predictions
    # model = load_model(MODEL_PATH)
    # predictions = predict(model, X_new)
    # save_predictions(predictions, OUTPUT_PATH)
    
    print("\nTo use this module in another script:")
    print("  from predict import load_model, predict, predict_batch")
