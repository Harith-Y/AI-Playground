# Auto-generated by AI-Playground
# Generated: 2025-12-30T21:33:31.957221
# Experiment: Customer Churn Prediction

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split


from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder
from sklearn.impute import SimpleImputer



import pickle
import json
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# Set random seed for reproducibility
RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)


# ============================================================================
# DATA LOADING
# ============================================================================

def load_data(file_path: str) -> pd.DataFrame:
    """
    Load dataset from file.
    
    Args:
        file_path: Path to the dataset file
    
    Returns:
        Loaded DataFrame
    """
    print(f"Loading data from {file_path}...")
    
    
    df = pd.read_csv(file_path)
    
    
    print(f"Loaded {len(df)} rows and {len(df.columns)} columns")
    print(f"Columns: {list(df.columns)}")
    
    return df


# Load the dataset
df = load_data('customer_data.csv')

# Display basic information
print("\nDataset Info:")
print(df.info())
print("\nFirst few rows:")
print(df.head())
print("\nBasic statistics:")
print(df.describe())


# ============================================================================
# DATA PREPROCESSING
# ============================================================================

def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Apply preprocessing steps to the dataset.
    
    Args:
        df: Input DataFrame
    
    Returns:
        Preprocessed DataFrame
    """
    df = df.copy()
    print("\nApplying preprocessing steps...")
    
    
    # Step 1: Impute Missing Values
    print(f"  - Impute missing values using mean strategy")
    
    # Handle missing values in age, income, tenure
    from sklearn.impute import SimpleImputer
    imputer = SimpleImputer(strategy='mean')
    df[['age', 'income', 'tenure']] = imputer.fit_transform(df[['age', 'income', 'tenure']])
    
    
    
    
    # Step 2: Standard Scaling
    print(f"  - Scale features using standard scaler")
    
    # Scale features: age, income, tenure
    
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    
    df[['age', 'income', 'tenure']] = scaler.fit_transform(df[['age', 'income', 'tenure']])
    
    
    
    
    # Step 3: OneHot Encoding
    print(f"  - Encode categorical features using onehot encoding")
    
    # Encode categorical features: gender, contract_type, payment_method
    
    from sklearn.preprocessing import OneHotEncoder
    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
    encoded = encoder.fit_transform(df[['gender', 'contract_type', 'payment_method']])
    encoded_df = pd.DataFrame(
        encoded,
        columns=encoder.get_feature_names_out(['gender', 'contract_type', 'payment_method']),
        index=df.index
    )
    df = df.drop(columns=['gender', 'contract_type', 'payment_method'])
    df = pd.concat([df, encoded_df], axis=1)
    
    
    
    
    
    
    print(f"Preprocessing complete. Shape: {df.shape}")
    return df


# Apply preprocessing
df = preprocess_data(df)